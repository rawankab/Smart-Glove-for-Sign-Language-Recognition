{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3P6yAeMcg1uP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "22d8e6ac-9c19-418c-eae3-c21a4eecf2e3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4d702551-c144-44bc-ab94-f932d465e570\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4d702551-c144-44bc-ab94-f932d465e570\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving sensor_data_with_labels.csv to sensor_data_with_labels.csv\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from io import StringIO\n",
        "\n",
        "# Assuming 'uploaded' contains your file data\n",
        "data = uploaded['sensor_data_with_labels.csv'].decode('utf-8')\n"
      ],
      "metadata": {
        "id": "mjmxslHDtLKR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean the data by replacing \",,\" with \",\"\n",
        "cleaned_data = data.replace(\",,\", \",\")\n",
        "\n",
        "# Recreate the StringIO object with the cleaned data\n",
        "data = StringIO(cleaned_data)\n",
        "\n",
        "# Specifying column names if they are known and consistent\n",
        "column_names = ['flex1', 'flex2', 'flex3', 'flex4', 'flex5', 'rolldeg', 'pitchdeg', 'headingDegrees', 'label']\n",
        "\n",
        "# Read the cleaned data into a DataFrame\n",
        "df = pd.read_csv(data, names=column_names, header=None, on_bad_lines='skip')\n",
        "\n",
        "# Show the first 20 rows of the DataFrame to verify the contents\n",
        "print(df.head(1000))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMxuHofqtLT2",
        "outputId": "0c4b5f87-f245-4cb5-e268-012445f29c44"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     flex1  flex2  flex3  flex4  flex5  rolldeg  pitchdeg  headingDegrees  \\\n",
            "0    15.51  12.00   2.92  214.0  200.0    263.0     126.0            76.0   \n",
            "1     5.95   5.61   5.00  212.0  196.0    263.0     126.0            80.0   \n",
            "2    10.76   5.14   3.96  204.0  197.0    263.0     127.0            56.0   \n",
            "3    -5.69  -4.38   3.22  207.0  196.0    263.0     127.0            83.0   \n",
            "4    -4.36  -2.18   3.96  206.0  196.0    263.0     126.0            84.0   \n",
            "..     ...    ...    ...    ...    ...      ...       ...             ...   \n",
            "995  41.11  -3.08   2.62  202.0  109.0     38.0     267.0           192.0   \n",
            "996  50.90 -19.43   7.38  197.0  109.0     43.0     267.0           190.0   \n",
            "997  55.06 -31.65   2.62  200.0  111.0     38.0     265.0           195.0   \n",
            "998  36.86 -50.99   2.62  200.0  108.0     42.0     267.0           193.0   \n",
            "999  24.48 -55.97   3.81  200.0  107.0     48.0     265.0           184.0   \n",
            "\n",
            "     label  \n",
            "0    Hello  \n",
            "1    Hello  \n",
            "2    Hello  \n",
            "3    Hello  \n",
            "4    Hello  \n",
            "..     ...  \n",
            "995    Yes  \n",
            "996    Yes  \n",
            "997    Yes  \n",
            "998    Yes  \n",
            "999    Yes  \n",
            "\n",
            "[1000 rows x 9 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Map the labels to numerical values\n",
        "# Display unique labels in the dataset\n",
        "unique_labels = df['label'].unique()\n",
        "print(\"Unique Labels in the Dataset:\", unique_labels)\n",
        "\n",
        "# Map the labels to numerical values\n",
        "# Display unique labels in the dataset\n",
        "unique_labels = df['label'].unique()\n",
        "print(\"Unique Labels in the Dataset:\", unique_labels)\n",
        "\n",
        "label_dict = {'Father': 0, 'Hello': 1, 'Me': 2, 'Mother': 3, 'Yes': 4, 'No': 5}\n",
        "df['label'] = df['label'].map(label_dict)\n",
        "print(df.head(100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBfnLkXWtLbp",
        "outputId": "3a03775a-e690-4e68-8352-e28f6de15457"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique Labels in the Dataset: ['Hello' 'Me' 'Father' 'Mother' 'Yes' 'No']\n",
            "Unique Labels in the Dataset: ['Hello' 'Me' 'Father' 'Mother' 'Yes' 'No']\n",
            "    flex1  flex2   flex3  flex4  flex5  rolldeg  pitchdeg  headingDegrees  \\\n",
            "0   15.51  12.00    2.92  214.0  200.0    263.0     126.0            76.0   \n",
            "1    5.95   5.61    5.00  212.0  196.0    263.0     126.0            80.0   \n",
            "2   10.76   5.14    3.96  204.0  197.0    263.0     127.0            56.0   \n",
            "3   -5.69  -4.38    3.22  207.0  196.0    263.0     127.0            83.0   \n",
            "4   -4.36  -2.18    3.96  206.0  196.0    263.0     126.0            84.0   \n",
            "..    ...    ...     ...    ...    ...      ...       ...             ...   \n",
            "95   2.46   6.26    2.69  187.0  197.0     67.0     263.0            80.0   \n",
            "96   2.03   4.97    3.29  188.0  195.0     74.0     261.0            82.0   \n",
            "97   1.31   4.38  273.96  189.0  199.0     74.0     261.0            82.0   \n",
            "98   0.65   2.38  273.96  190.0  197.0     75.0     261.0            83.0   \n",
            "99   1.95   3.25    5.00  188.0  202.0     72.0     261.0            83.0   \n",
            "\n",
            "    label  \n",
            "0       1  \n",
            "1       1  \n",
            "2       1  \n",
            "3       1  \n",
            "4       1  \n",
            "..    ...  \n",
            "95      2  \n",
            "96      2  \n",
            "97      2  \n",
            "98      2  \n",
            "99      2  \n",
            "\n",
            "[100 rows x 9 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Remove duplicate rows\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "# Handling missing values\n",
        "# Option 1: Remove rows with any null values\n",
        "df = df.dropna()\n"
      ],
      "metadata": {
        "id": "3uCyBBvjtLgC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "# Separating features and labels\n",
        "X = df.drop(columns=\"label\")\n",
        "y = df[\"label\"]\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# First split: Separate 80% for training, 20% for a combined test/validation set\n",
        "X_train_val, X_temp_test, y_train_val, y_temp_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "X_test, X_val, y_test, y_val = train_test_split(\n",
        "    X_temp_test, y_temp_test, test_size=0.5, random_state=42, stratify=y_temp_test\n",
        ")\n",
        "\n",
        "# Print the sizes of each set and their label distribution to verify correctness\n",
        "print(\"Training Set Size:\", len(y_train_val))\n",
        "print(\"Validation Set Size:\", len(y_val))\n",
        "print(\"Test Set Size:\", len(y_test))\n",
        "\n",
        "print(\"\\nLabel Distribution in Training Set:\\n\", y_train_val.value_counts(normalize=True))\n",
        "print(\"Label Distribution in Validation Set:\\n\", y_val.value_counts(normalize=True))\n",
        "print(\"Label Distribution in Test Set:\\n\", y_test.value_counts(normalize=True))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xh7rwgsJtLlC",
        "outputId": "0d61c9ef-89ff-4c91-b2e4-e9cbc92b3f7c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Set Size: 957\n",
            "Validation Set Size: 120\n",
            "Test Set Size: 120\n",
            "\n",
            "Label Distribution in Training Set:\n",
            " label\n",
            "3    0.211076\n",
            "0    0.205852\n",
            "1    0.202717\n",
            "4    0.166144\n",
            "5    0.166144\n",
            "2    0.048067\n",
            "Name: proportion, dtype: float64\n",
            "Label Distribution in Validation Set:\n",
            " label\n",
            "3    0.208333\n",
            "0    0.208333\n",
            "1    0.200000\n",
            "4    0.166667\n",
            "5    0.166667\n",
            "2    0.050000\n",
            "Name: proportion, dtype: float64\n",
            "Label Distribution in Test Set:\n",
            " label\n",
            "3    0.216667\n",
            "1    0.200000\n",
            "0    0.200000\n",
            "5    0.166667\n",
            "4    0.166667\n",
            "2    0.050000\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming y_train_val, y_test, and y_val are already defined Series from your data splitting process.\n",
        "\n",
        "# Count the number of samples for each label in the training set\n",
        "train_label_counts = y_train_val.value_counts()\n",
        "print(\"Number of samples per label in the Training Set:\")\n",
        "print(train_label_counts)\n",
        "\n",
        "# Count the number of samples for each label in the test set\n",
        "test_label_counts = y_test.value_counts()\n",
        "print(\"\\nNumber of samples per label in the Test Set:\")\n",
        "print(test_label_counts)\n",
        "\n",
        "# Count the number of samples for each label in the validation set\n",
        "validation_label_counts = y_val.value_counts()\n",
        "print(\"\\nNumber of samples per label in the Validation Set:\")\n",
        "print(validation_label_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YO-IZVpotiHe",
        "outputId": "34c12ed2-66f8-4945-dcf4-ece30886fabb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples per label in the Training Set:\n",
            "label\n",
            "3    202\n",
            "0    197\n",
            "1    194\n",
            "4    159\n",
            "5    159\n",
            "2     46\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Number of samples per label in the Test Set:\n",
            "label\n",
            "3    26\n",
            "1    24\n",
            "0    24\n",
            "5    20\n",
            "4    20\n",
            "2     6\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Number of samples per label in the Validation Set:\n",
            "label\n",
            "3    25\n",
            "0    25\n",
            "1    24\n",
            "4    20\n",
            "5    20\n",
            "2     6\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Initialize the SVM classifier\n",
        "svm_model = SVC(kernel='linear', random_state=42)  # You can change the kernel based on your data characteristics\n",
        "\n",
        "# Train the model\n",
        "svm_model.fit(X_train_val, y_train_val)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "ai2bnbjitiKT",
        "outputId": "1a173dc2-3f56-489f-9ec1-98a7a68e7730"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(kernel='linear', random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;, random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions on the validation set\n",
        "y_val_pred = svm_model.predict(X_val)\n",
        "\n",
        "# Calculate accuracy\n",
        "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
        "print(f\"Validation Accuracy: {val_accuracy:.2%}\")\n",
        "# Detailed classification report\n",
        "print(\"\\nClassification Report on Validation Set:\")\n",
        "print(classification_report(y_val, y_val_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHafZgzhtiNN",
        "outputId": "64b4e3ec-f0b2-4c66-b4c0-b6ec770289c9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 94.17%\n",
            "\n",
            "Classification Report on Validation Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.92      0.88        25\n",
            "           1       0.96      1.00      0.98        24\n",
            "           2       1.00      1.00      1.00         6\n",
            "           3       0.91      0.84      0.87        25\n",
            "           4       1.00      1.00      1.00        20\n",
            "           5       1.00      0.95      0.97        20\n",
            "\n",
            "    accuracy                           0.94       120\n",
            "   macro avg       0.95      0.95      0.95       120\n",
            "weighted avg       0.94      0.94      0.94       120\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from joblib import dump, load\n",
        "# Save the scaler and model\n",
        "dump(scaler, 'scaler.pkl')\n",
        "dump(svm_model, 'model.pkl')\n",
        "\n",
        "# Optionally download to your local machine\n",
        "files.download('scaler.pkl')\n",
        "files.download('model.pkl')\n"
      ],
      "metadata": {
        "id": "OZ8QY2ZdttPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Expanded parameter grid\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],  # Extended range including smaller values\n",
        "    'kernel': ['linear', 'rbf', 'poly'],  # Adding polynomial kernel\n",
        "    'gamma': [0.001, 0.01, 0.1, 1, 'scale', 'auto'],  # Finer range of values\n",
        "    'degree': [2, 3, 4],  # Only relevant for 'poly' kernel\n",
        "    'coef0': [0, 1]  # Coefficient for polynomial and sigmoid kernels\n",
        "}\n",
        "\n",
        "# Grid search with cross-validation\n",
        "grid_search = GridSearchCV(SVC(), param_grid, cv=5, scoring='accuracy', verbose=1)\n",
        "grid_search.fit(X_train_val, y_train_val)\n",
        "\n",
        "# Best parameters and best score\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "print(f\"Best cross-validation accuracy: {grid_search.best_score_:.2%}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uel8WP_FttSX",
        "outputId": "c7920523-7e57-4c67-979a-a5fcba177c85"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 540 candidates, totalling 2700 fits\n",
            "Best parameters: {'C': 10, 'coef0': 1, 'degree': 2, 'gamma': 1, 'kernel': 'poly'}\n",
            "Best cross-validation accuracy: 99.69%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-evaluate using the best parameters\n",
        "svm_model = grid_search.best_estimator_\n",
        "y_val_pred = svm_model.predict(X_val)\n",
        "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
        "print(f\"Updated Validation Accuracy: {val_accuracy:.2%}\")\n",
        "\n",
        "# Predictions on the test set\n",
        "y_test_pred = svm_model.predict(X_test)\n",
        "\n",
        "# Calculate test accuracy\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "print(f\"Test Accuracy: {test_accuracy:.2%}\")\n",
        "\n",
        "# Detailed classification report for test set\n",
        "print(\"\\nClassification Report on Test Set:\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZfxJY3LttXx",
        "outputId": "174e2e88-7ee7-401e-8303-3802d2486450"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated Validation Accuracy: 99.17%\n",
            "Test Accuracy: 98.33%\n",
            "\n",
            "Classification Report on Test Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.96      0.96        24\n",
            "           1       1.00      1.00      1.00        24\n",
            "           2       1.00      1.00      1.00         6\n",
            "           3       0.96      0.96      0.96        26\n",
            "           4       1.00      1.00      1.00        20\n",
            "           5       1.00      1.00      1.00        20\n",
            "\n",
            "    accuracy                           0.98       120\n",
            "   macro avg       0.99      0.99      0.99       120\n",
            "weighted avg       0.98      0.98      0.98       120\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import learning_curve\n",
        "\n",
        "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
        "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
        "\n",
        "    plt.figure()\n",
        "    plt.title(title)\n",
        "    if ylim is not None:\n",
        "        plt.ylim(*ylim)\n",
        "    plt.xlabel(\"Training examples\")\n",
        "    plt.ylabel(\"Score\")\n",
        "    train_sizes, train_scores, test_scores = learning_curve(\n",
        "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "    plt.grid()\n",
        "\n",
        "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
        "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
        "                     color=\"r\")\n",
        "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
        "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
        "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
        "             label=\"Training score\")\n",
        "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
        "             label=\"Cross-validation score\")\n",
        "\n",
        "    plt.legend(loc=\"best\")\n",
        "    return plt\n",
        "\n",
        "# Assuming 'svm_model' is your trained SVM model\n",
        "title = 'Learning Curves (SVM, Polynomial kernel, C=0.01)'\n",
        "cv = 5  # Cross-validation strategy\n",
        "plot_learning_curve(svm_model, title, X, y, (0, 1.01), cv=cv, n_jobs=4)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "4VHF1mTpttbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# Now we will train a random forest model on the training data\n",
        "rf_clf = RandomForestClassifier(random_state=42)\n",
        "rf_clf.fit(X_train_val, y_train_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "4lfoZp6duGr7",
        "outputId": "5b75f22c-a9bd-4e2f-8e70-fd39e789e9f4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "# Now we use the trained Random Forest model to make predictions on the validation set\n",
        "y_val_pred = rf_clf.predict(X_val)\n",
        "\n",
        "# Calculating the accuracy of the model on the validation set\n",
        "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
        "\n",
        "# Printing out the accuracy\n",
        "print(\"Validation Set Accuracy:\", val_accuracy)\n",
        "\n",
        "# To also predict and show the accuracy on the test set:\n",
        "y_test_pred = rf_clf.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "print(\"Test Set Accuracy:\", test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vclA3CtAuGu-",
        "outputId": "b19c8ab4-12bc-4181-8de5-8047aa6751e9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Set Accuracy: 1.0\n",
            "Test Set Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjusting the model parameters to combat overfitting\n",
        "rf_clf_adjusted = RandomForestClassifier(\n",
        "    n_estimators=100,    # Default number of trees. Try increasing if necessary.\n",
        "    max_depth=10,        # Maximum depth of the tree to limit complexity.\n",
        "    min_samples_split=4, # Minimum number of samples required to split a node.\n",
        "    min_samples_leaf=2,  # Minimum number of samples required at a leaf node.\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Training the adjusted model\n",
        "rf_clf_adjusted.fit(X_train_val, y_train_val)\n",
        "\n",
        "# Evaluating the adjusted model\n",
        "y_val_pred_adjusted = rf_clf_adjusted.predict(X_val)\n",
        "y_test_pred_adjusted = rf_clf_adjusted.predict(X_test)\n",
        "\n",
        "val_accuracy_adjusted = accuracy_score(y_val, y_val_pred_adjusted)\n",
        "test_accuracy_adjusted = accuracy_score(y_test, y_test_pred_adjusted)\n",
        "\n",
        "print(\"Adjusted Validation Set Accuracy:\", val_accuracy_adjusted)\n",
        "print(\"Adjusted Test Set Accuracy:\", test_accuracy_adjusted)\n",
        "print(classification_report(y_test, y_test_pred_adjusted))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UwyuwT7uGz8",
        "outputId": "dabbeefc-3a56-4cff-ca14-06c332d547b4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adjusted Validation Set Accuracy: 1.0\n",
            "Adjusted Test Set Accuracy: 0.9916666666666667\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98        24\n",
            "           1       1.00      1.00      1.00        24\n",
            "           2       1.00      1.00      1.00         6\n",
            "           3       0.96      1.00      0.98        26\n",
            "           4       1.00      1.00      1.00        20\n",
            "           5       1.00      1.00      1.00        20\n",
            "\n",
            "    accuracy                           0.99       120\n",
            "   macro avg       0.99      0.99      0.99       120\n",
            "weighted avg       0.99      0.99      0.99       120\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7cab2JA1uG5J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}